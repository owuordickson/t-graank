{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb109aaf-2d81-424d-80a5-156d565cbb04",
   "metadata": {},
   "source": [
    "# Extracting Crop EVI from Kenyan Towns\n",
    "\n",
    "We extract Crop EVI from: Nairobi (NRB), Makueni (MAK), Kakamega (KAK) and Wajir (WAJ)\n",
    "\n",
    "**Products used:** \n",
    "* [ls7_sr](https://explorer.digitalearth.africa/ls7_sr)\n",
    "* [ls8_sr](https://explorer.digitalearth.africa/ls8_sr)\n",
    "* [ls9_sr](https://explorer.digitalearth.africa/ls9_sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9aace7-6646-4f44-8ed6-222d2733dedc",
   "metadata": {},
   "source": [
    "## Background\n",
    "[Enhanced Vegetation Index](https://shorturl.at/oHRY9) can be calculated from Landsat or Sentinel-2 images, and is similar to the Normalized Difference Vegetation Index (NDVI), as it quantifies vegetation greenness. However, the EVI corrects for some atmospheric conditions and canopy background noise and is more sensitive in areas with dense vegetation.\n",
    "\n",
    "Using Digital Earth Africa's archive of analysis-ready satellite data, we can easily calculate the EVI for mapping and monitoring vegetation through time, or as inputs to machine learning or classification algorithms.\n",
    "\n",
    "## Description\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "1. Load Landsat 7 images for an area of interest (AOI)\n",
    "2. Calculate the Enhanced Vegetation Index (EVI)\n",
    "3. Compute average EVA and save results in CSV file\n",
    "4. Visualize the results.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385fe32a-fcae-4052-9cd6-5b741925dbb8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4123b3-2d61-4be5-8c33-e4a2faf14a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.utils.geometry import Geometry\n",
    "\n",
    "from deafrica_tools.datahandling import load_ard, mostcommon_crs\n",
    "from deafrica_tools.plotting import rgb\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.areaofinterest import define_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be0cc5-80ce-4485-8b10-d5cc1f634552",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27596d0a-c61e-4448-a941-87a3a89b4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='crop_health_evi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bcd4a7-0286-404d-8d47-3950a191ea04",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis over.\n",
    "The parameters are\n",
    "\n",
    "* `lat`: The central latitude to analyse (e.g. `10.338`).\n",
    "* `lon`: The central longitude to analyse (e.g. `-1.055`).\n",
    "* `buffer`: The number of square degrees to load around the central latitude and longitude.\n",
    "For reasonable loading times, set this as `0.1` or lower.\n",
    "\n",
    "\n",
    "#### Select location\n",
    "To define the area of interest, there are two methods available:\n",
    "\n",
    "1. By specifying the latitude, longitude, and buffer. This method requires you to input the central latitude, central longitude, and the buffer value in square degrees around the center point you want to analyze. For example, `lat = 10.338`, `lon = -1.055`, and `buffer = 0.1` will select an area with a radius of 0.1 square degrees around the point with coordinates (10.338, -1.055).\n",
    "\n",
    "2. By uploading a polygon as a `GeoJSON or Esri Shapefile`. If you choose this option, you will need to upload the geojson or ESRI shapefile into the Sandbox using Upload Files button <img align=\"top\" src=\"../Supplementary_data/upload_files_icon.png\"> in the top left corner of the Jupyter Notebook interface. ESRI shapefiles must be uploaded with all the related files `(.cpg, .dbf, .shp, .shx)`. Once uploaded, you can use the shapefile or geojson to define the area of interest. Remember to update the code to call the file you have uploaded.\n",
    "\n",
    "To use one of these methods, you can uncomment the relevant line of code and comment out the other one. To comment out a line, add the `\"#\"` symbol before the code you want to comment out. By default, the first option which defines the location using latitude, longitude, and buffer is being used.\n",
    "\n",
    "**If running the notebook for the first time**, keep the default settings below.\n",
    "This will demonstrate how the analysis works and provide meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e1c6c7-9e22-4377-b761-fa91af4cdba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Specify the latitude, longitude, and buffer\n",
    "aoi = define_area(lat=-1.319456, lon=36.852516, buffer=0.02)  # NRB\n",
    "#aoi = define_area(lat=3.355112, lon=39.738751, buffer=0.02)  # WAJ\n",
    "#aoi = define_area(lat=0.292923, lon=34.759233, buffer=0.02)  # KAK\n",
    "#aoi = define_area(lat=-2.282646, lon=31.41094, buffer=0.02)  # MAK\n",
    "\n",
    "#Create a geopolygon and geodataframe of the area of interest\n",
    "geopolygon = Geometry(aoi[\"features\"][0][\"geometry\"], crs=\"epsg:4326\")\n",
    "geopolygon_gdf = gpd.GeoDataFrame(geometry=[geopolygon], crs=geopolygon.crs)\n",
    "\n",
    "# Get the latitude and longitude range of the geopolygon\n",
    "lat_range = (geopolygon_gdf.total_bounds[1], geopolygon_gdf.total_bounds[3])\n",
    "lon_range = (geopolygon_gdf.total_bounds[0], geopolygon_gdf.total_bounds[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f8c015-5061-4cea-a6a0-5af991674cf6",
   "metadata": {},
   "source": [
    "## Create a query and load satellite data\n",
    "\n",
    "The `load_ard` function will automatically mask out clouds from the dataset, allowing us to focus on pixels that contain useful data.\n",
    "It will also exclude images where more than 99% of the pixels are masked, which is set using the `min_gooddata` parameter in the `load_ard` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7036b3f1-346c-47ef-bedd-bf2efecad5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/deafrica_tools/datahandling.py:739: UserWarning: Multiple UTM zones ['epsg:32637', 'epsg:32636'] were returned for this query. Defaulting to the most common zone: epsg:32637\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pixel quality parameters for USGS Collection 2\n",
      "Finding datasets\n",
      "    ls7_sr\n",
      "Counting good quality pixels for each time step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/rasterio/warp.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dest = _reproject(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering to 54 out of 327 time steps with at least 99.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Re-scaling Landsat C2 data\n",
      "Loading 54 time steps\n"
     ]
    }
   ],
   "source": [
    "# Create a reusable query\n",
    "query = {\n",
    "    'x': lon_range,\n",
    "    'y': lat_range,\n",
    "    'time': ('2000-01-01', '2022-12-31'),\n",
    "    'resolution': (-10, 10)\n",
    "}\n",
    "\n",
    "# Identify the most common projection system in the input query\n",
    "# product = 'ls7_sr'\n",
    "# product = 'ls8_sr'\n",
    "# product = 'ls9_sr'\n",
    "output_crs = mostcommon_crs(dc=dc, product='ls7_sr', query=query)\n",
    "\n",
    "# Load available data from Landsat 9 and filter to retain only times\n",
    "# with at least 99% good data\n",
    "ds = load_ard(dc=dc,\n",
    "              products=['ls7_sr'],\n",
    "              min_gooddata=0.99,\n",
    "              measurements=['red', 'green', 'blue', 'nir'],\n",
    "              output_crs=output_crs,\n",
    "              **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5478b2-1e83-41c0-8400-9c36f5a77391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EVI using `calculate indices`\n",
    "ds = calculate_indices(ds, index='EVI', satellite_mission='ls')\n",
    "\n",
    "#The vegetation proxy index should now appear as a data variable,\n",
    "#along with the loaded measurements, in the `ds` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956e4b5a-d3a0-448f-a4cc-a20c93cddc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved average EVI data to 'average_evi.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'ds' is your dataset with EVI values over time, loaded using calculate_indices\n",
    "# And it contains a 'time' dimension and 'EVI' data variable\n",
    "\n",
    "# 1. Compute the mean EVI for each time point\n",
    "evi_avg_over_time = ds['EVI'].mean(dim=['x', 'y'])  # Adjust dims to match your spatial dimensions\n",
    "\n",
    "# 2. Convert to a Pandas DataFrame\n",
    "evi_avg_df = evi_avg_over_time.to_dataframe().reset_index()\n",
    "\n",
    "# 3. Rename columns and format data as required\n",
    "evi_avg_df = evi_avg_df[['time', 'EVI']]  # Select only time and EVI columns\n",
    "evi_avg_df.columns = ['date', 'EVI']  # Rename columns\n",
    "\n",
    "# 4. Save to CSV\n",
    "evi_avg_df.to_csv(\"average_evi_nrb.csv\", index=False)\n",
    "#evi_avg_df.to_csv(\"average_evi_mak.csv\", index=False)\n",
    "#evi_avg_df.to_csv(\"average_evi_waj.csv\", index=False)\n",
    "#evi_avg_df.to_csv(\"average_evi_kak.csv\", index=False)\n",
    "print(\"Saved average EVI data to 'average_evi.csv'\")\n",
    "\n",
    "# evi_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1949713-c3e5-4912-9619-eb8948a86097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the selected EVI results at timestep 1, 10, 15 and last image\n",
    "#ds.isel(time=[1, 10, 15, -1]).EVI.plot(col='time',\n",
    "#                                       cmap='RdYlGn',\n",
    "#                                       size=6,\n",
    "#                                       col_wrap=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
